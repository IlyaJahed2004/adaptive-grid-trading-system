{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd86bf4f",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4702a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from numpy import log\n",
    "from itertools import combinations\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d19f9c",
   "metadata": {},
   "source": [
    "### Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf93c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TAO-USD: possibly delisted; no price data found  (1d 2023-01-01 -> 2026-01-01)\n",
      "$PEPE-USD: possibly delisted; no price data found  (1d 2023-01-01 -> 2026-01-01)\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = False\n",
    "\n",
    "# --------------------- CoinMarketCap: get top coins ---------------------\n",
    "API_KEY = \"13e10784c3884bb8b374a661da8b4631\"  # keep this secret in real projects\n",
    "url = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest\"\n",
    "headers = {\"Accepts\": \"application/json\", \"X-CMC_PRO_API_KEY\": API_KEY}\n",
    "params = {\"start\": \"1\", \"limit\": \"70\", \"convert\": \"USD\"}\n",
    "\n",
    "\n",
    "# request the top coins by market cap\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "data = response.json()[\"data\"]\n",
    "# build a small DataFrame with symbols only\n",
    "top70_df = pd.DataFrame([{\"symbol\": coin[\"symbol\"]} for coin in data])\n",
    "\n",
    "#  backtest / history parameters\n",
    "# Backtest start and end (tz-aware UTC timestamps)\n",
    "BACKTEST_START = pd.Timestamp(\"2025-01-01\", tz=\"UTC\")\n",
    "BACKTEST_END   = pd.Timestamp(\"2025-12-31\", tz=\"UTC\")\n",
    "HISTORY_START  = \"2023-01-01\"   # earliest date to fetch history (ensures enough pre-backtest data)\n",
    "TARGET_N = 50                   # target number of assets to select\n",
    "\n",
    "# --------------------- Phase 1: Universe selection by EMA200 ratio ---------------------\n",
    "selected = []   # list of selected tickers (pass EMA filter)\n",
    "main_dict = {}  # store full historical df for each selected ticker (used later for backtest)\n",
    "crypto_pointer = 0\n",
    "\n",
    "# iterate through top coins until we select TARGET_N assets or exhaust the list\n",
    "while len(selected) < TARGET_N and crypto_pointer < len(top70_df):\n",
    "    symbol = top70_df.iloc[crypto_pointer][\"symbol\"]\n",
    "    crypto_pointer += 1\n",
    "    ticker = symbol + \"-USD\"\n",
    "\n",
    "    # fetch daily historical OHLC data (include time through backtest end)\n",
    "    hist = yf.Ticker(ticker).history(\n",
    "        interval=\"1d\",\n",
    "        start=HISTORY_START,\n",
    "        end=(BACKTEST_END + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    # skip tickers with no usable price data\n",
    "    if hist.empty or hist[\"Close\"].isna().all():\n",
    "        continue\n",
    "\n",
    "    # keep only the needed columns and convert index to a timestamp column\n",
    "    df = hist[[\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "    df.rename(columns={\"Date\": \"timestamp\"}, inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "    # ensure all timestamps are timezone-aware and in UTC to avoid tz comparison errors\n",
    "    if df[\"timestamp\"].dt.tz is None:\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].dt.tz_convert(\"UTC\")\n",
    "\n",
    "\n",
    "\n",
    "    # ticker passed the EMA filter -> store full df (we will slice BACKTEST range at backtest time)\n",
    "    selected.append(ticker)\n",
    "    main_dict[ticker] = df\n",
    "\n",
    "# print selected tickers summary\n",
    "if VERBOSE:\n",
    "    print(\"Selected count:\", len(selected))\n",
    "    print(selected)\n",
    "    print(\"------------------\")\n",
    "\n",
    "# --------------------- applying EMA200 filter----------------------\n",
    "ema200_filtered_tickers = []\n",
    "for ticker in selected:\n",
    "    df = main_dict[ticker]\n",
    "    # build the pre-backtest slice (use only data strictly before BACKTEST_START)\n",
    "    pre_df = df.loc[df[\"timestamp\"] < BACKTEST_START].copy()\n",
    "    # require at least 200 historical candles to compute a reliable EMA200\n",
    "    if len(pre_df) < 200:\n",
    "        continue\n",
    "\n",
    "    # compute EMA200 on pre-backtest data only (avoids lookahead)\n",
    "    pre_df.loc[:, \"EMA200\"] = pre_df[\"Close\"].ewm(span=200, adjust=False).mean()\n",
    "\n",
    "    # compute the fraction of pre-backtest closes that are above EMA200\n",
    "    ratio_above = (pre_df[\"Close\"] > pre_df[\"EMA200\"]).mean()\n",
    "\n",
    "    # apply the >60% rule: keep the ticker only if more than half of closes were above EMA200\n",
    "    if ratio_above <= 0.6:\n",
    "        continue\n",
    "    ema200_filtered_tickers.append(ticker)\n",
    "if VERBOSE:\n",
    "    print(\"filtered by ema tickers:\", len(ema200_filtered_tickers))\n",
    "    print(ema200_filtered_tickers)\n",
    "\n",
    "# --------------------- ATR-based grid spacing ---------------------\n",
    "ATR_PERIOD = 14\n",
    "GRID_MULTIPLIER = 1.0   # spacing = GRID_MULTIPLIER * ATR\n",
    "MIN_HISTORY_FOR_ATR = ATR_PERIOD\n",
    "\n",
    "spacing_meta = {}  # will hold last_atr, spacing and spacing% for each ticker\n",
    "\n",
    "def compute_atr_series(df, period=14):\n",
    "    \"\"\"\n",
    "    Compute ATR series for a DataFrame with 'High','Low','Close'.\n",
    "    Returns a pandas Series of the ATR (NaN for the first `period-1` rows).\n",
    "    \"\"\"\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    close = df[\"Close\"]\n",
    "    prev_close = close.shift(1)\n",
    "\n",
    "    # True Range components and the TR per row\n",
    "    tr = pd.concat([\n",
    "        (high - low).abs(),\n",
    "        (high - prev_close).abs(),\n",
    "        (low - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    # ATR as a simple rolling mean of TR (min_periods=period => first valid after `period` rows)\n",
    "    atr = tr.rolling(window=period, min_periods=period).mean()\n",
    "    return atr\n",
    "\n",
    "\n",
    "\n",
    "# compute ATR and derive grid spacing for each selected ticker\n",
    "for ticker in ema200_filtered_tickers:\n",
    "    df_all = main_dict[ticker]\n",
    "    df = df_all.copy()\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])  # ensure datetime\n",
    "\n",
    "    # use only data before the backtest start to compute ATR (no lookahead)\n",
    "    pre_df = df.loc[df[\"timestamp\"] < BACKTEST_START].copy()\n",
    "    if len(pre_df) < MIN_HISTORY_FOR_ATR:\n",
    "        # not enough data to compute ATR(period)\n",
    "        continue\n",
    "\n",
    "    # compute ATR series on pre-backtest data\n",
    "    pre_df.loc[:, \"ATR\"] = compute_atr_series(pre_df, period=ATR_PERIOD)\n",
    "\n",
    "    # take the last ATR value as representative recent volatility\n",
    "    last_atr = pre_df[\"ATR\"].iloc[-1]\n",
    "    if pd.isna(last_atr):\n",
    "        # ATR may be NaN if there weren't enough TR values; skip in that case\n",
    "        continue\n",
    "\n",
    "    # grid spacing in price units (e.g., USD)\n",
    "    grid_spacing = GRID_MULTIPLIER * last_atr\n",
    "\n",
    "    # also compute spacing as a percent of last close for convenience\n",
    "    last_close = pre_df[\"Close\"].iloc[-1]\n",
    "    grid_spacing_pct = grid_spacing / last_close if last_close != 0 else None\n",
    "\n",
    "    spacing_meta[ticker] = {\n",
    "        \"last_atr\": float(last_atr),\n",
    "        \"grid_spacing\": float(grid_spacing),\n",
    "        \"grid_spacing_pct\": float(grid_spacing_pct) if grid_spacing_pct is not None else None,\n",
    "        \"last_close\": float(last_close)\n",
    "    }\n",
    "if VERBOSE:\n",
    "    print(\"------------------\")\n",
    "    # print spacing summary for each ticker\n",
    "    for t, meta in spacing_meta.items():\n",
    "        print(f\"{t}: ATR={meta['last_atr']:.4f}, spacing={meta['grid_spacing']:.4f}, spacing%={meta['grid_spacing_pct']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01e448",
   "metadata": {},
   "source": [
    "### Grid Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115550c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_levels(current_price, grid_spacing, n_levels=8):\n",
    "    \"\"\"\n",
    "    Create grid levels below the current market price.\n",
    "    \"\"\"\n",
    "    buy_levels = np.array([current_price - (i + 1) * grid_spacing for i in range(n_levels)])\n",
    "    if VERBOSE:\n",
    "        print(f\"this is the buy levels: {buy_levels}\" )\n",
    "    sell_levels = buy_levels + grid_spacing  # Sell level is 1 grid step above buy level\n",
    "    if VERBOSE:\n",
    "        print(f\"this is the sell levels: {sell_levels}\" )\n",
    "    return buy_levels, sell_levels\n",
    "\n",
    "\n",
    "\n",
    "def compute_martingale_sizes(base_size, multiplier, n_levels):\n",
    "    \"\"\"\n",
    "    Compute exponentially increasing position sizes for grid levels.\n",
    "    \"\"\"\n",
    "    sizes = []\n",
    "\n",
    "    for i in range(n_levels):\n",
    "        size = base_size * (multiplier ** i)\n",
    "        sizes.append(size)\n",
    "    if VERBOSE:\n",
    "        print(f\"this is the position sizes: {sizes}\")\n",
    "    return sizes\n",
    "\n",
    "\n",
    "# Just for testing the compute_average_price method and it is not used for strategy implementation.\n",
    "filled_buys = [\n",
    "    {\"buy_price\": 100, \"size\": 1},\n",
    "    {\"buy_price\": 90,  \"size\": 2},\n",
    "    {\"buy_price\": 80,  \"size\": 4},\n",
    "]\n",
    "\n",
    "\n",
    "def compute_average_price(positions):\n",
    "    \"\"\"\n",
    "    Compute weighted average buy price of ACTIVE (open) positions.\n",
    "    Expects each position dict to have keys: 'buy' and 'size'.\n",
    "    \"\"\"\n",
    "    total_cost = 0.0\n",
    "    total_size = 0.0\n",
    "\n",
    "    for p in positions:\n",
    "        total_cost += p[\"buy\"] * p[\"size\"]\n",
    "        total_size += p[\"size\"]\n",
    "\n",
    "    if total_size == 0:\n",
    "        return None\n",
    "\n",
    "    return total_cost / total_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1792010",
   "metadata": {},
   "source": [
    "### Martingale Grid (Long Only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add84ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running timeframe: 1d\n",
      "2025-01 | tested: 17\n",
      "2025-02 | tested: 16\n",
      "2025-03 | tested: 16\n",
      "2025-04 | tested: 16\n",
      "2025-05 | tested: 16\n",
      "2025-06 | tested: 16\n",
      "2025-07 | tested: 16\n",
      "2025-08 | tested: 16\n",
      "2025-09 | tested: 16\n",
      "2025-10 | tested: 16\n",
      "2025-11 | tested: 16\n",
      "2025-12 | tested: 16\n",
      "Running timeframe: 4h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-01-01 00:00:00+00:00 -> 2025-02-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-02-01 00:00:00+00:00 -> 2025-03-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-03-01 00:00:00+00:00 -> 2025-04-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-04-01 00:00:00+00:00 -> 2025-05-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-05-01 00:00:00+00:00 -> 2025-06-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-06-01 00:00:00+00:00 -> 2025-07-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-07-01 00:00:00+00:00 -> 2025-08-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-08-01 00:00:00+00:00 -> 2025-09-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-09-01 00:00:00+00:00 -> 2025-10-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-10-01 00:00:00+00:00 -> 2025-11-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-11-01 00:00:00+00:00 -> 2025-12-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (4h 2025-12-01 00:00:00+00:00 -> 2026-01-01 00:00:00+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12 | tested: 16\n",
      "Running timeframe: 1h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-01-01 00:00:00+00:00 -> 2025-02-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-02-01 00:00:00+00:00 -> 2025-03-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-03-01 00:00:00+00:00 -> 2025-04-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-04-01 00:00:00+00:00 -> 2025-05-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-05-01 00:00:00+00:00 -> 2025-06-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-06-01 00:00:00+00:00 -> 2025-07-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-07-01 00:00:00+00:00 -> 2025-08-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-08-01 00:00:00+00:00 -> 2025-09-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-09-01 00:00:00+00:00 -> 2025-10-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-10-01 00:00:00+00:00 -> 2025-11-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-11-01 00:00:00+00:00 -> 2025-12-01 23:59:59+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11 | tested: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USDE-USD: possibly delisted; no price data found  (1h 2025-12-01 00:00:00+00:00 -> 2026-01-01 00:00:00+00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12 | tested: 16\n",
      "Saved phase3_monthly_results.csv\n",
      "\n",
      "=== Aggregated summary by timeframe ===\n",
      "timeframe  mean_monthly_pnl  mean_monthly_trades  tp_rate  sl_fraction\n",
      "       1d       1258.584599             2.186528 0.326425     0.020725\n",
      "       1h       2097.005409             3.609375 0.635417     0.015625\n",
      "       4h       1510.450905             3.135417 0.598958     0.015625\n"
     ]
    }
   ],
   "source": [
    "#  Phase 3 : monthly multi-timeframe grid runner \n",
    "\n",
    "# Parameters:\n",
    "N_LEVELS = 10\n",
    "USE_BUY_LEVELS = 8\n",
    "BASE_SIZE = 1.5\n",
    "MARTINGALE_MULTIPLIER = 2.0\n",
    "TAKE_PROFIT_PCT = 0.025\n",
    "STOP_LOSS_INDEX = N_LEVELS - 1\n",
    "\n",
    "TIMEFRAMES = [\"1d\", \"4h\", \"1h\"]  \n",
    "\n",
    "#  helper method:\n",
    "def initialize_grid_positions(buy_levels, sell_levels, sizes):\n",
    "    return [\n",
    "        {\"id\": i, \"buy\": float(buy_levels[i]), \"sell\": float(sell_levels[i]), \"size\": float(sizes[i]), \"open\": False}\n",
    "        for i in range(len(buy_levels))\n",
    "    ]\n",
    "\n",
    "def run_grid_strategy_month_reentry(\n",
    "    close_series,\n",
    "    grid_spacing,\n",
    "    n_levels=10,\n",
    "    base_size=1.5,\n",
    "    martingale_multiplier=2.0,\n",
    "    use_buy_levels=8,\n",
    "    take_profit_pct=0.025,\n",
    "    stop_loss_index=9,\n",
    "    max_cycles_per_month=None,\n",
    "    allow_immediate_reentry=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Monthly grid runner with re-entry after basket take profit.\n",
    "\n",
    "    Behavior:\n",
    "    - Build grid anchored at first price of close_series.\n",
    "    - Trade intra-month; on basket TP: close all opens, rebuild grid at current price, continue.\n",
    "    - Stop-loss is checked against current grid's buy_levels[stop_loss_index].\n",
    "    - If max_cycles_per_month is set, caps the number of rebuilds per month.\n",
    "    - If allow_immediate_reentry is True, the same price bar after rebuild may trigger immediate buys.\n",
    "    \"\"\"\n",
    "\n",
    "    # defensive: empty series\n",
    "    if not close_series:\n",
    "        return {\"realized_pnl\": 0.0, \"trades\": 0, \"tp_hits\": 0, \"sl_hit\": False, \"cycles_run\": 0}\n",
    "\n",
    "    pnl = 0.0\n",
    "    trades = 0\n",
    "    tp_hits = 0\n",
    "    sl_hit = False\n",
    "    cycles = 0\n",
    "\n",
    "    i = 0\n",
    "    L = len(close_series)\n",
    "\n",
    "    # ---------- initialize first grid ----------\n",
    "    ref_price = float(close_series[0])\n",
    "    buy_levels, sell_levels = create_grid_levels(ref_price, grid_spacing, n_levels)\n",
    "    sizes = compute_martingale_sizes(base_size, martingale_multiplier, n_levels)\n",
    "    positions = initialize_grid_positions(buy_levels, sell_levels, sizes)\n",
    "    cycles += 1\n",
    "\n",
    "    # ensure stop_loss_index valid for the grid\n",
    "    if stop_loss_index >= len(positions):\n",
    "        stop_loss_index = len(positions) - 1\n",
    "    if stop_loss_index < 0:\n",
    "        stop_loss_index = 0\n",
    "\n",
    "    # ---------- main loop ----------\n",
    "    while i < L:\n",
    "        price = float(close_series[i])\n",
    "\n",
    "        # ---------- BUYS ----------\n",
    "        for p in positions[:use_buy_levels]:\n",
    "            if not p[\"open\"] and price <= p[\"buy\"]:\n",
    "                p[\"open\"] = True\n",
    "                trades += 1\n",
    "\n",
    "        # ---------- INDIVIDUAL GRID SELLS ----------\n",
    "        for p in positions:\n",
    "            if p[\"open\"] and price >= p[\"sell\"]:\n",
    "                p[\"open\"] = False\n",
    "                pnl += (p[\"sell\"] - p[\"buy\"]) * p[\"size\"]\n",
    "                trades += 1\n",
    "\n",
    "        # ---------- BASKET TAKE PROFIT ----------\n",
    "        open_positions = [p for p in positions if p[\"open\"]]\n",
    "        avg = compute_average_price(open_positions)  # pass only open positions (defensive)\n",
    "\n",
    "        if avg is not None and price >= avg * (1 + take_profit_pct):\n",
    "            # close all open positions at market price\n",
    "            for p in open_positions:\n",
    "                p[\"open\"] = False\n",
    "                pnl += (price - p[\"buy\"]) * p[\"size\"]\n",
    "                trades += 1\n",
    "\n",
    "            tp_hits += 1\n",
    "\n",
    "            # cycle cap check\n",
    "            if max_cycles_per_month is not None and cycles >= max_cycles_per_month:\n",
    "                # do not rebuild further, finish month\n",
    "                break\n",
    "\n",
    "            # ---------- REBUILD GRID anchored at current price ----------\n",
    "            buy_levels, sell_levels = create_grid_levels(price, grid_spacing, n_levels)\n",
    "            sizes = compute_martingale_sizes(base_size, martingale_multiplier, n_levels)\n",
    "            positions = initialize_grid_positions(buy_levels, sell_levels, sizes)\n",
    "            cycles += 1\n",
    "\n",
    "            # re-validate stop_loss_index for new grid\n",
    "            if stop_loss_index >= len(positions):\n",
    "                stop_loss_index = len(positions) - 1\n",
    "            if stop_loss_index < 0:\n",
    "                stop_loss_index = 0\n",
    "\n",
    "            # allow immediate buys on same price if requested\n",
    "            if allow_immediate_reentry:\n",
    "                # do not increment i, let loop re-process same price with new grid\n",
    "                continue\n",
    "            else:\n",
    "                # proceed to next bar\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        # ---------- STOP LOSS (based on current grid's buy level at stop_loss_index) ----------\n",
    "        # Use the current grid's buy level (no buffer) as the SL trigger:\n",
    "        current_stop_level = positions[stop_loss_index][\"buy\"]\n",
    "        if price < current_stop_level:\n",
    "            # close all open positions at market price and terminate month\n",
    "            for p in positions:\n",
    "                if p[\"open\"]:\n",
    "                    p[\"open\"] = False\n",
    "                    pnl += (price - p[\"buy\"]) * p[\"size\"]\n",
    "                    trades += 1\n",
    "            sl_hit = True\n",
    "            break\n",
    "\n",
    "        # move to next price bar\n",
    "        i += 1\n",
    "\n",
    "    return {\n",
    "        \"realized_pnl\": pnl,\n",
    "        \"trades\": trades,\n",
    "        \"tp_hits\": tp_hits,\n",
    "        \"sl_hit\": sl_hit,\n",
    "        \"cycles_run\": cycles\n",
    "    }\n",
    "\n",
    "\n",
    "# build month windows \n",
    "month_starts = pd.date_range(start=BACKTEST_START, end=BACKTEST_END, freq=\"MS\").to_pydatetime().tolist()\n",
    "\n",
    "# storage for results \n",
    "records = []  # one row per (ticker, month, timeframe)\n",
    "\n",
    "# ---------- sanity: require phase1 outputs ----------\n",
    "if \"spacing_meta\" not in globals() or \"main_dict\" not in globals():\n",
    "    raise SystemExit(\"spacing_meta or main_dict not found. Run Phase 1/1.5 first.\")\n",
    "\n",
    "# ---------- build month windows ----------\n",
    "month_starts = pd.date_range(start=BACKTEST_START, end=BACKTEST_END, freq=\"MS\").to_pydatetime().tolist()\n",
    "\n",
    "# ---------- run: timeframe -> month -> ticker ----------\n",
    "records = []  # collect (ticker, month, timeframe, metrics)\n",
    "\n",
    "for tf in TIMEFRAMES:\n",
    "    print(f\"Running timeframe: {tf}\")\n",
    "    for i, start_dt in enumerate(month_starts):\n",
    "        end_dt = (month_starts[i+1] - timedelta(seconds=1)) if i+1 < len(month_starts) else BACKTEST_END\n",
    "        month_label = start_dt.strftime(\"%Y-%m\")\n",
    "        tested = 0\n",
    "\n",
    "        for ticker, meta in spacing_meta.items():\n",
    "            try:\n",
    "                # get month data for this timeframe\n",
    "                if tf == \"1d\":\n",
    "                    df_all = main_dict.get(ticker)\n",
    "                    if df_all is None:\n",
    "                        continue\n",
    "                    df_month = df_all.loc[(df_all[\"timestamp\"] >= start_dt) & (df_all[\"timestamp\"] <= end_dt)].copy()\n",
    "                    used_tf = \"1d\"\n",
    "                else:\n",
    "                    # fetch intraday for the month (no fallback)\n",
    "                    df_month = yf.Ticker(ticker).history(interval=tf, start=start_dt, end=end_dt + timedelta(days=1))\n",
    "                    if df_month is None or df_month.empty:\n",
    "                        continue\n",
    "                    df_month = df_month.reset_index()\n",
    "                    # normalize first datetime-like column to 'timestamp'\n",
    "                    dt_col = df_month.columns[0]\n",
    "                    df_month = df_month.rename(columns={dt_col: \"timestamp\"})\n",
    "                    df_month[\"timestamp\"] = pd.to_datetime(df_month[\"timestamp\"])\n",
    "                    used_tf = tf\n",
    "\n",
    "                # require Close column and chronological order\n",
    "                if \"Close\" not in df_month.columns or df_month.empty:\n",
    "                    continue\n",
    "                df_month = df_month.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "                # grid anchored at first close of month\n",
    "                ref_price = float(df_month[\"Close\"].iloc[0])\n",
    "                spacing = meta[\"grid_spacing\"]\n",
    "\n",
    "                buy_levels, sell_levels = create_grid_levels(ref_price, spacing, n_levels=N_LEVELS)\n",
    "                sizes = compute_martingale_sizes(BASE_SIZE, MARTINGALE_MULTIPLIER, n_levels=N_LEVELS)\n",
    "\n",
    "                close_series = df_month[\"Close\"].tolist()\n",
    "                metrics = run_grid_strategy_month_reentry(\n",
    "                    close_series=close_series,\n",
    "                    grid_spacing=spacing,        \n",
    "                    n_levels=N_LEVELS,\n",
    "                    base_size=BASE_SIZE,\n",
    "                    martingale_multiplier=MARTINGALE_MULTIPLIER,\n",
    "                    use_buy_levels=USE_BUY_LEVELS,\n",
    "                    take_profit_pct=TAKE_PROFIT_PCT,\n",
    "                    stop_loss_index=STOP_LOSS_INDEX,\n",
    "                    max_cycles_per_month=None,    \n",
    "                    allow_immediate_reentry=True\n",
    "                )\n",
    "\n",
    "                records.append({\n",
    "                    \"ticker\": ticker,\n",
    "                    \"month\": month_label,\n",
    "                    \"timeframe\": used_tf,\n",
    "                    \"realized_pnl\": metrics[\"realized_pnl\"],\n",
    "                    \"trades\": metrics[\"trades\"],\n",
    "                    \"tp_hits\": metrics[\"tp_hits\"],\n",
    "                    \"sl_hit\": metrics[\"sl_hit\"],\n",
    "                    \"ref_price\": ref_price,\n",
    "                    \"spacing\": spacing\n",
    "                })\n",
    "                tested += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # minimal error reporting, continue others\n",
    "                print(f\"[{month_label}][{ticker}][{tf}] error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if tested:\n",
    "            print(f\"{month_label} | tested: {tested}\")\n",
    "\n",
    "# ---------- save results ----------\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "results_df.to_csv(\"phase3_monthly_results_minimal.csv\", index=False)\n",
    "print(\"Saved phase3_monthly_results.csv\")\n",
    "\n",
    "# quick aggregated summary per timeframe\n",
    "if not results_df.empty:\n",
    "    summary = results_df.groupby(\"timeframe\").agg(\n",
    "        mean_monthly_pnl = (\"realized_pnl\", \"mean\"),\n",
    "        mean_monthly_trades = (\"trades\", \"mean\"),\n",
    "        tp_rate = (\"tp_hits\", \"mean\"),\n",
    "        sl_fraction = (\"sl_hit\", \"mean\")\n",
    "    ).reset_index()\n",
    "    print(\"\\n=== Aggregated summary by timeframe ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"No results collected.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
